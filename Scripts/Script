#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
#%    Data Acquisition    		          %
#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
##Paquetes 
rm(list = ls())


require("pacman")
p_load("devtools")
p_load("ggpubr")
devtools::install_github("thomasp85/patchwork")
p_load(readxl)
p_load(rvest)
p_load(ggplot2)
p_load(patchwork)
p_load(rio) 
p_load(tidyverse)
p_load(e1071) 
p_load(EnvStats) 
p_load(tidymodels) 
p_load(ggplot2) 
p_load(scales) 
p_load(ggpubr) 
p_load(knitr) 
p_load(kableExtra)
p_load(broom)
p_load(caret)
p_load(haven)
p_load(corrplot)
p_load(psych)


#---------Importar bases de datos

##Se leen las bases de datos de la Encuesta de cultura Política 2015 y 2017

##Año 2015

CaracteristicasGenerales2015 <- read_dta("2015/Caracteristicas Generales.dta")
Democracia2015 = read_sav("2015/Democracia.sav")
EleccionesyPartidos2015 = read_sav("2015/Elecciones y Partidos.sav")
Fuerzatrabajo2015 = read_sav("2015/Fuerza de Trabajo.sav")
Participacion2015 = read_sav("2015/Participación.sav")
Viviendas2015 = read_sav("2015/Tabla viviendas.sav")

##Año 2017

CaracteristicasGenerales2017 <- read_sav("2017/Características Generales.sav")
Democracia2017 = read_sav("2017/Democracia.sav")
EleccionesyPartidos2017 = read_dta("2017/Elecciones y Partidos.dta")
Caracteristicas22017 = read_sav("2017/Características 2.sav")
Participacion2017 = read_sav("2017/Participación.sav")
Viviendas2017 = read_sav("2017/Tabla viviendas.sav")


##Inscripción de cedulas y datos del MOE

Cedulas_inscritas <- read_excel("MOE_Inscripción.xlsx")
Resultados_Presi_20182davuelta <- read_excel("MOE-Result.Presi.xlsx")
Resultados_Alc_2015 <- read_excel("MOE.Result.Alcaldia2015.xlsx")
Riesgos_elec <- read_excel("MOE_riesgos.xlsx")

##Los NAS en las siguientes variables significan que no hay presencia de estos grupos, por los que se les dará un valor de cero
Riesgos_elec$`PBCO 2018` <- ifelse(is.na(Riesgos_elec$`PBCO 2018`), 0, Riesgos_elec$`PBCO 2018`)
Riesgos_elec$`ELN 2018` <- ifelse(is.na(Riesgos_elec$`ELN 2018`), 0, Riesgos_elec$`ELN 2018`)
Riesgos_elec$`AU ELN 2018` <- ifelse(is.na(Riesgos_elec$`AU ELN 2018`), 0, Riesgos_elec$`AU ELN 2018`)
Riesgos_elec$`AUC 2015` <- ifelse(is.na(Riesgos_elec$`AUC 2015`), 0, Riesgos_elec$`AUC 2015`)
Riesgos_elec$`ELN 2015` <- ifelse(is.na(Riesgos_elec$`ELN 2015`), 0, Riesgos_elec$`ELN 2015`)
Riesgos_elec$`ELN 2016` <- ifelse(is.na(Riesgos_elec$`ELN 2016`), 0, Riesgos_elec$`ELN 2016`)
Riesgos_elec$`FARC 2015` <- ifelse(is.na(Riesgos_elec$`FARC 2015`), 0, Riesgos_elec$`FARC 2015`)
Riesgos_elec$`FARC 2016` <- ifelse(is.na(Riesgos_elec$`FARC 2016`), 0, Riesgos_elec$`FARC 2016`)
Riesgos_elec$`Guerrilas 2015` <- ifelse(is.na(Riesgos_elec$`Guerrilas 2015`), 0, Riesgos_elec$`Guerrilas 2015`)
Riesgos_elec$`PBCO 2015` <- ifelse(is.na(Riesgos_elec$`PBCO 2015`), 0, Riesgos_elec$`PBCO 2015`)
Riesgos_elec$`PBCO 2016` <- ifelse(is.na(Riesgos_elec$`PBCO 2016`), 0, Riesgos_elec$`PBCO 2016`)
Riesgos_elec$`PBCO 2018` <- ifelse(is.na(Riesgos_elec$`PBCO 2018`), 0, Riesgos_elec$`PBCO 2018`)

##Se crean consolidados por año

EncuestaPolitica_2015 <- merge(CaracteristicasGenerales2015, Democracia2015, # Data frames u objectos a ser transformados
                               by = c("DIRECTORIO", "HOGAR_NUMERO", "PERSONA_NUMERO"))

EncuestaPolitica_2015 <- merge(EncuestaPolitica_2015, EleccionesyPartidos2015, # Data frames u objectos a ser transformados
                               by = c("DIRECTORIO", "HOGAR_NUMERO", "PERSONA_NUMERO"), no.dups = TRUE)

EncuestaPolitica_2015 <- merge(EncuestaPolitica_2015, Participacion2015, # Data frames u objectos a ser transformados
                               by = c("DIRECTORIO", "HOGAR_NUMERO", "PERSONA_NUMERO"), no.dups = TRUE)

EncuestaPolitica_2015 <- merge(EncuestaPolitica_2015, Fuerzatrabajo2015, # Data frames u objectos a ser transformados
                               by = c("DIRECTORIO", "HOGAR_NUMERO", "PERSONA_NUMERO"), no.dups = TRUE)

EncuestaPolitica_2015 <- merge(EncuestaPolitica_2015, Viviendas2015, # Data frames u objectos a ser transformados
                               by = c("DIRECTORIO"), no.dups = TRUE, all.x = TRUE, all.y = TRUE)


EncuestaPolitica_2017 <- merge(CaracteristicasGenerales2017, Democracia2017, # Data frames u objectos a ser transformados
                               by = c("DIRECTORIO", "HOGAR_NUMERO", "PERSONA_NUMERO"))

EncuestaPolitica_2017 <- merge(EncuestaPolitica_2017, EleccionesyPartidos2017, # Data frames u objectos a ser transformados
                               by = c("DIRECTORIO", "HOGAR_NUMERO", "PERSONA_NUMERO"), no.dups = TRUE)

EncuestaPolitica_2017 <- merge(EncuestaPolitica_2017, Participacion2017, # Data frames u objectos a ser transformados
                               by = c("DIRECTORIO", "HOGAR_NUMERO", "PERSONA_NUMERO"), no.dups = TRUE)

EncuestaPolitica_2017 <- merge(EncuestaPolitica_2017, Caracteristicas22017, # Data frames u objectos a ser transformados
                               by = c("DIRECTORIO", "HOGAR_NUMERO", "PERSONA_NUMERO"), no.dups = TRUE)

EncuestaPolitica_2017 <- merge(EncuestaPolitica_2017, Viviendas2017, # Data frames u objectos a ser transformados
                               by = c("DIRECTORIO"), no.dups = TRUE, all.x = TRUE, all.y = TRUE)


##Consolidados MOE
MOE_2015 <- merge(Cedulas_inscritas, Riesgos_elec, # Data frames u objectos a ser transformados
                  by = c("Code DANE"), no.dups = TRUE)

names(Resultados_Alc_2015)[names(Resultados_Alc_2015) == "Code Dane"] <- "Code DANE"
MOE_2015 <- merge(MOE_2015, Resultados_Alc_2015, # Data frames u objectos a ser transformados
                  by = c("Code DANE"), no.dups = TRUE)

MOE_2017 <- merge(Cedulas_inscritas, Riesgos_elec, # Data frames u objectos a ser transformados
                  by = c("Code DANE"), no.dups = TRUE)

names(Resultados_Presi_20182davuelta)[names(Resultados_Presi_20182davuelta) == "Code"] <- "Code DANE"
MOE_2017 <- merge(MOE_2017, Resultados_Presi_20182davuelta, # Data frames u objectos a ser transformados
                  by = c("Code DANE"), no.dups = TRUE)


##Se agregan las variables por region y se pegan las dos bases 

MOE_2017 = aggregate(MOE_2017,
                     by = list(MOE_2017$REGION),
                     FUN = mean)

MOE_2015 = aggregate(MOE_2015,
                     by = list(MOE_2015$REGION),
                     FUN = mean)

EncuestaPolitica_2015 <- merge(EncuestaPolitica_2015, MOE_2015, # Data frames u objectos a ser transformados
                               by = c("REGION"), no.dups = TRUE, all.x = TRUE, all.y = FALSE)

EncuestaPolitica_2017 <- merge(EncuestaPolitica_2017, MOE_2017, # Data frames u objectos a ser transformados
                               by = c("REGION"), no.dups = TRUE, all.x = TRUE, all.y = FALSE)



##Hay seis observaciones duplicadas, entonces se eliminan
which(duplicated(names(EncuestaPolitica_2015)))
EncuestaPolitica_2015 = subset(EncuestaPolitica_2015, select = -c(FEX_P.x,NRO_ENCUESTA.x, NRO_ENCUESTA.y ) )
which(duplicated(names(EncuestaPolitica_2017)))
EncuestaPolitica_2017= subset(EncuestaPolitica_2017, select = -c(FEX_P.x,NRO_ENCUESTA.x, NRO_ENCUESTA.y) )


##Ahora se corrigen las variables para que sean leídas como categóricas, bulein o string dependiendo del caso. 
##Lo anterior, ya que en su mayoría fueron leídas como enteros.
##Se definen entonces las variables categóricas


EncuestaPolitica_2015 <- EncuestaPolitica_2015 %>%
  mutate_at(.vars = c("P4000" , "P4031S1","P4031S1A1", "P4031S2", "P4031S3", "P4031S4", "P4031S4A1",
                      "P4031S5", "P4090", "P70", "REGION", "P220", "P6008", "P605", "P6050", "P6160", "P6210", "P6210S1",     
                      "P6945", "P8586", "P606", "PERSONA_NUMERO", "P5332S6", "P5334S2", "P5334S3", "P5334S4", "P5334S5", "P5334S6", "P5334S7",       
                      "P5368S1", "P5368S2", "P5368S3", "P5368S4",  "P5368S5", "P5368S6", "P5368S7", "P5368S8" ,      
                      "P5373S1", "P5373S10", "P5373S11", "P5373S12", "P5373S2", "P5373S3" , "P5373S4", "P5373S5",       
                      "P5373S6", "P5373S7", "P5373S8", "P5373S9", "P5376S1" , "P5376S2", "P5376S3",       
                      "P5376S4", "P5376S5", "P5376S6",  "P5386", "P5389S1", "P5389S10", "P5389S11", "P5389S2",       
                      "P5389S3", "P5389S4", "P5389S5", "P5389S6", "P5389S7", "P5389S8", "P5389S9", "P5393",         
                      "P5396S1" ,  "P5396S2", "P5396S3", "P5396S4", "P5396S5", "P5396S6", "P5400S1", "P5400S2",       
                      "P5400S3", "P5400S4", "P5400S5", "P5400S6", "P5400S7", "P5400S8",  "P5322S3",    
                      "P5322S4", "P5323", "P5324S2", "P5324S3", "P5324S4", "P5324S5", "P5325S1", "P5325S2",      
                      "P5325S3", "P5325S4", "P5325S5", "P5325S6", "P5326" ,"P5327", "P5335",         
                      "P5336S1", "P5336S10", "P5336S11", "P5336S12", "P5336S2", "P5336S3", "P5336S4", "P5336S5" ,       
                      "P5336S6", "P5336S7", "P5336S8", "P5336S9", "P5337S1", "P5337S2", "P5337S3",  "P5337S4",     
                      "P5337S5", "P5337S6", "P5337S7", "P5338S1", "P5338S2", "P5338S3", "P5338S4", "P5338S5",       
                      "P5338S6", "P6933" , "P517", "P5264S1", "P5264S2", "P5264S3", "P5264S4","P5264S5",        
                      "P5264S6", "P5264S7", "P5265", "P5266S1", "P5266S2", "P5266S3", "P5266S4", "P5266S5",        
                      "P5266S6", "P5266S7", "P5266S8", "P5272S1", "P5272S2", "P5272S3", "P5272S4", "P5272S5", "P5272S6","P5272S7",               
                      "P5307S1" , "P5307S2", "P5307S3", "P5307S4","P5307S5",  "P5308", "P5315S1", "P5315S2",      
                      "P5315S3" ,"P5315S4", "P5315S5","P5315S6", "P5315S7", "P5315S8","P5319",  "P6934S1",      
                      "P6934S2","P6934S3","P6934S4" ,"P6934S5", "P6934S6" , "P6934S7" , "P6936S1" ,    "P6936S2",
                      "P6936S3", "P6936S4", "P6936S5", "P6936S6","P6936S7","P6937S1","P6937S2" , "P6937S3" ,     
                      "P6937S4","P6937S5","P6938S1","P6938S2",  "P6938S3", "P6938S4" , "P6939S1" ,  "P6939S2",      
                      "P6939S3","P6939S4" ,"P6939S5", "P6939S6" ,"P6939S7", "P6939S8", "P6939S9",  "P6942S1",      
                      "P6942S10" ,"P6942S11","P6942S2","P6942S3", "P6942S4","P6942S5", "P6942S6" , "P6942S7"  ,    
                      "P6942S8","P6942S9", "P6943S1" , "P6943S2" ,"P6943S3",  "P6943S4", "P6944S1","P6944S2" ,     
                      "P6944S3","P6944S4" , "P6944S5" , "P6944S6", "P6944S7"),
            .funs = factor)

EncuestaPolitica_2017<- EncuestaPolitica_2017  %>%
  mutate_at(.vars = c("REGION", "P4090", "P4000", "P4031S1", "P4031S1A1", "P4031S2", "P4031S3",
                      "P4031S4", "P4031S4A1", "P4031S5", "P70", "NRO_ENCUESTA", "HOGAR_NUMERO", "PERSONA_NUMERO",
                      "P6008", "P220", "P1069", "P1069S1", "P6050", "P605", "P6160", "P8586", "P6210S1", "P6945", "P606", "P5368S1",
                      "P5368S2", "P5368S3", "P5368S4", "P5368S5", "P5368S6", "P5368S7", "P5368S8", "P5334S2", "P5334S3", "P5334S4", "P5334S5", "P5334S6",
                      "P5334S7", "P5373S1", "P5373S10", "P5373S12", "P5373S11", "P5373S2", "P5373S3", "P5373S4", "P5373S5", "P5373S6", "P5373S7", "P5373S8",
                      "P5373S9", "P5376S1", "P5376S2", "P5376S3", "P5376S4", "P5376S5", "P5376S6", "P5386", "P5389S1", "P5389S2", "P5389S3", "P5389S4", "P5389S5",
                      "P5389S6", "P5389S7", "P5389S8", "P5389S9", "P5389S10", "P5389S11", "P5393", "P5396S1", "P5396S2", "P5396S3", "P5396S4", "P5396S5", "P5396S6",
                      "P5400S1", "P5400S2", "P5400S3", "P5400S4", "P5400S5", "P5400S6", "P5400S7", "P5400S8", "P5332S6", "P5335", "P5336S1", "P5336S2", 
                      "P5336S3", "P5336S4", "P5336S5", "P5336S6", "P5336S7", "P5336S8", "P5336S9", "P5336S10", "P5336S11", "P5336S12", "P5337S1", "P5337S2", "P5337S3",
                      "P5337S4", "P5337S5", "P5337S6", "P5337S7", "P5338S1", "P5338S2", "P5338S3", "P5338S4", "P5338S5", "P5338S6", "P5321S1", "P5321S2", "P5321S3", 
                      "P5321S4", "P5321S5", "P5321S6", "P5321S7", "P5321S8", "P5321S9", "P5322S1","P5322S2", "P5322S3", "P5322S4", "P5323", "P5324S2", "P5324S3", "P5324S4",
                      "P5324S5", "P5327", "P5315S1", "P5315S2", "P5315S3", "P5315S4", 
                      "P5315S5", "P5315S6", "P5315S7", "P5315S8", "P5319", "P5307S1", "P5307S2", "P5307S3", "P5307S4", "P5307S5", "P6934S1", "P6934S2",
                      "P6934S3", "P6934S4", "P6934S5", "P6934S6", "P6934S7", "P6936S1", "P6936S2", "P6936S3", "P6936S4", "P6936S5", "P6936S6", "P6936S7", "P517", 
                      "P5264S1", "P5264S2", "P5264S3", "P5264S4", "P5264S5", "P5264S6", "P5264S7", "P5265", "P5266S1", "P5266S2", "P5266S3", "P5266S4", "P5266S5",
                      "P5266S6", "P5266S7", "P5266S8", "P5272S1", "P5272S2", "P5272S3", "P5272S4", "P5272S5", "P5272S6", "P5272S7", "P6939S2", "P6939S3", "P6939S4", 
                      "P6939S5", "P6939S6", "P1764S1", "P1764S2", "P1764S3", "P1764S4", "P1764S5", "P1764S6", "P1764S7", "P1764S8", "P1758", "P6943S2", "P6943S3", 
                      "P6943S4", "P1754", "P1753", "P1752", "P1751", "P1749", "P1750", "P6944S1", "P6944S2", "P6944S3", "P6944S4", "P6944S5", "P6944S6", "P6944S7"), .funs = factor)


str(EncuestaPolitica_2015)
dim(EncuestaPolitica_2015)
##---------Tratamiento de missing values 2015

cantidad_na <- sapply(EncuestaPolitica_2015, function(x) sum(is.na(x))) #Una función que me suma el número de NAs por variable
cantidad_na <- data.frame(cantidad_na) #Lo convierto en Data Frame
porcentaje_na <- cantidad_na/nrow(EncuestaPolitica_2015) #Le saco el porcentaje de Missing values a cada variable

# Porcentaje de observaciones faltantes. 
porcentaje <- mean(porcentaje_na[,1]) #El 20.39% de las variables tiene NAs
print(paste0("En promedio el ", round(porcentaje*100, 2), "% de las entradas están vacías"))

##Ordenamos de mayor a menor
porcentaje_na <- arrange(porcentaje_na, desc(cantidad_na))
# Convertimos el nombre de la fila en columna
porcentaje_na <- rownames_to_column(porcentaje_na, "variable")

# Quitamos las variables que no tienen NAs
filtro <- porcentaje_na$cantidad_na == 0
variables_sin_na <- porcentaje_na[filtro, "variable"]
str_count(variables_sin_na) #Hay 48 variables sin NA
variables_sin_na <- paste(variables_sin_na, collapse = ", ")
print(paste("Las variables sin NAs son:", variables_sin_na))

porcentaje_na <- porcentaje_na[!filtro,] #Quedan 307 variables con NAs

orden <- porcentaje_na$variable[length(porcentaje_na$variable):1] #Se vuelven caracteres
porcentaje_na$variable <- factor(porcentaje_na$variable,
                                 levels = orden) #Se utilizan como factores para poder graficar

str(porcentaje_na) # Se revisa el tipo de variables

# Como son tantas variables vamos a hacer una gráfica con los que tienen menos NAs
#para analizar si se pueden imputar los valores

ggplot(porcentaje_na[1:30,], 
       aes(y = variable, x = cantidad_na)) +
  geom_bar(stat = "identity", fill = "darkslategray3") +
  geom_text(aes(label = paste0(round(100*cantidad_na, 1), "%")),
            colour = "white", position = "dodge", hjust = 1.3,
            size = 2, fontface = "bold") +
  theme_classic() +
  labs(x = "Porcentaje de NAs", y = "Variables") +
  scale_x_continuous(labels = scales::percent, limits = c(0, 1))


#Si la cantidad de missing values es superior al 5% no se pueden imputar los datos (crearlos a partir de la media o la moda)
##Se eliminan las variables que tienen más del 10% de NAs
filtro2 <- porcentaje_na$cantidad_na > 0.05
variables_eliminadas <- porcentaje_na$variable[filtro2]
EP_2015_clean <- EncuestaPolitica_2015 %>%
  select(-variables_eliminadas) 
k0 <- ncol(EncuestaPolitica_2015)
k1 <- ncol(EP_2015_clean)
print(paste("Se eliminaron", k0-k1, "variables. Ahora la base tiene", k1, "columnas."))
#Ahora solo tenemos 263 variables

porcentaje_na %>%
  filter(cantidad_na <= 0.05) 
#Nos quedan 215 variables con NAs

porcentaje_na %>%
  filter(cantidad_na <= 0.05) 

##---------Tratamiento de missing values 2017

cantidad_na <- sapply(EncuestaPolitica_2017, function(x) sum(is.na(x))) #Una función que me suma el número de NAs por variable
cantidad_na <- data.frame(cantidad_na) #Lo convierto en Data Frame
porcentaje_na <- cantidad_na/nrow(EncuestaPolitica_2017) #Le saco el porcentaje de Missing values a cada variable

# Porcentaje de observaciones faltantes. 
porcentaje <- mean(porcentaje_na[,1]) #El 16.08% de las variables tiene NAs
print(paste0("En promedio el ", round(porcentaje*100, 2), "% de las entradas están vacías"))

##Ordenamos de mayor a menor
porcentaje_na <- arrange(porcentaje_na, desc(cantidad_na))
# Convertimos el nombre de la fila en columna
porcentaje_na <- rownames_to_column(porcentaje_na, "variable")

# Quitamos las variables que no tienen NAs
filtro <- porcentaje_na$cantidad_na == 0
variables_sin_na <- porcentaje_na[filtro, "variable"]
str_count(variables_sin_na) #Hay 56 variables sin NA
variables_sin_na <- paste(variables_sin_na, collapse = ", ")
print(paste("Las variables sin NAs son:", variables_sin_na))

porcentaje_na <- porcentaje_na[!filtro,] #Quedan 307 variables con NAs

orden <- porcentaje_na$variable[length(porcentaje_na$variable):1] #Se vuelven caracteres
porcentaje_na$variable <- factor(porcentaje_na$variable,
                                 levels = orden) #Se utilizan como factores para poder graficar

str(porcentaje_na) # Se revisa el tipo de variables

# Como son tantas variables vamos a hacer una gráfica con los que tienen menos NAs
#para analizar si se pueden imputar los valores

ggplot(porcentaje_na[1:30,], 
       aes(y = variable, x = cantidad_na)) +
  geom_bar(stat = "identity", fill = "darkslategray3") +
  geom_text(aes(label = paste0(round(100*cantidad_na, 1), "%")),
            colour = "white", position = "dodge", hjust = 1.3,
            size = 2, fontface = "bold") +
  theme_classic() +
  labs(x = "Porcentaje de NAs", y = "Variables") +
  scale_x_continuous(labels = scales::percent, limits = c(0, 1))


#Si la cantidad de missing values es superior al 5% no se pueden imputar los datos (crearlos a partir de la media o la moda)
##Se eliminan las variables que tienen más del 10% de NAs
filtro2 <- porcentaje_na$cantidad_na > 0.05
variables_eliminadas <- porcentaje_na$variable[filtro2]
EP_2017_clean <- EncuestaPolitica_2017 %>%
  select(-variables_eliminadas) 
k0 <- ncol(EncuestaPolitica_2017)
k1 <- ncol(EP_2017_clean)
print(paste("Se eliminaron", k0-k1, "variables. Ahora la base tiene", k1, "columnas."))
#Ahora solo tenemos 262 variables

porcentaje_na %>%
  filter(cantidad_na <= 0.05) 
#Nos quedan 206 variables con NAs

porcentaje_na %>%
  filter(cantidad_na <= 0.05) 

###-----Imputación de variables de interés:
##P6933--> Variable dependiente de interés (Factor)

#Si la cantidad de missing values es superior al 5% no se pueden imputar los datos (crearlos a partir de la media o la moda)
##Se eliminan las variables que tienen más del 5% de NAs

#--------------Año 2015
filtro <- !sapply(EP_2015_clean, is.factor)
categoricas <- names(EP_2015_clean)[filtro]
myvars <- c("P4031S1A1", "P220", "v3")

calc_mode <- function(x){
  
  # List the distinct / unique values
  distinct_values <- unique(x)
  
  # Count the occurrence of each distinct value
  distinct_tabulate <- tabulate(match(x, distinct_values))
  
  # Return the value with the highest occurrence
  distinct_values[which.max(distinct_tabulate)]
}


for (i in categoricas) {
  EP_2015_clean <- EP_2015_clean  %>% 
    mutate(i = if_else(is.na(i), 
                       calc_mode(i), 
                       i))
}




#La moda es la categoría más repetida, se prueba si el loop funcionó para todas las categóricas

##Ahora para las continuas

filtro <- !sapply(EP_2015_clean, is.numeric)
numericas <- names(EP_2015_clean)[filtro]


for (x in numericas) {
  
  EP_2015_clean <- EP_2015_clean %>%
    mutate(x = ifelse(is.na(x), median(x, na.rm = T), x))
}



#Variables de interés: P4031S1A1, P220, P6050,  P6160, P6210, P606, P203, P5368S2, P5368S6, P5334S2, P5334S3, P5334S4, 
#P5334S7, P5373S2, P5373S4, P5373S5, P5373S6, P5373S7, P5373S9, P5374, P5386, P5389S10, P5393, P5396S1, P5396S3,
#P5400S1, P5400S3, P5400S5, P5400S6, P5400S7, P5336S1, P5336S2, P5336S3, P5336S4, P5336S5, P5336S6, P5336S7, P5336S8,
#P5336S9, P5337S1, P5337S2, P5337S3, P5337S4, P5337S5, P5339S1, P5321S7, P5321S8,
#P5323, P5325S1, P5325S2, P5325S3, P5325S4, P6936S1, P6936S2, P6936S3, P6936S4, P6936S5, P6936S6, P6936S7,
#P517,  P5264S1,  P5264S2,  P5264S3,  P5264S4,  P5264S5,  P5264S6, P6939S6, P1754

# Numericas: P5785, P5465, P203, P5328, P5322S1, P5322S2, P5322S3, P5322S4,  P5263S10,
#P5263S12, P5263S14, P5263S2,

EP_2015_clean <- EP_2015_clean %>% drop_na("P5785", "P5465", "P5785", "P5465", "P203", "P5328", "P5322S1", "P5322S2", "P5322S3", "P5322S4",  "P5263S10",
                                           "P5263S14", "P5263S2")

EP_2015_clean <- EP_2015_clean  %>% 
  mutate(P4031S1A1 = if_else(is.na(P4031S1A1), 
                             calc_mode(P4031S1A1), 
                             P4031S1A1))
EP_2015_cleanF <- EP_2015_clean[c("P6933", "P5785", "P5465", "P203", "P5328", "P5322S1", "P5322S2", "P5322S3", "P5322S4",  "P5263S10",
                                  "P5263S14", "P5263S2", "P4031S1A1", "P220", "P6050",  "P6160", "P6210", "P606", "P5368S2", "P5368S6", "P5334S2", "P5334S3", "P5334S4", 
                                  "P5334S7", "P5374", "P5389S10", "P5339S1", "P5321S7", "P5321S8",
                                  "P5323", "P6936S1", "P6936S2", "P6936S3", "P6936S4", "P6936S5", "P6936S6", "P6936S7", "P517", "P6939S6", "ELN 2015", "FARC 2015", "AUC 2015",
                                  "Tasa de Inscripción de cédulas 2015 (inscritos por mil habitantes)")]

#--------------Año 2017
filtro <- !sapply(EP_2017_clean, is.factor)
categoricas <- names(EP_2017_clean)[filtro]

for (i in categoricas) {
  EP_2017_clean <- EP_2017_clean  %>% 
    mutate(i = if_else(is.na(i), 
                       calc_mode(i), 
                       i))
}


#La moda es la categoría más repetida, se prueba si el loop funcionó para todas las categóricas

#Variables de interés P4031S1A1, P220, P6050,  P6160, P6210, P606, P203, P5368S2, P5368S6, P5334S2, P5334S3, P5334S4, 
#P5334S7, P5373S2, P5373S4, P5373S5, P5373S6, P5373S7, P5373S9, P5374, P5386, P5389S10, P5393, P5396S1, P5396S3,
#P5400S1, P5400S3, P5400S5, P5400S6, P5400S7, P5336S1, P5336S2, P5336S3, P5336S4, P5336S5, P5336S6, P5336S7, P5336S8,
#P5336S9, P5337S1, P5337S2, P5337S3, P5337S4, P5337S5, P5339S1, P5321S7, P5321S8,
#P5323, P5325S1, P5325S2, P5325S3, P5325S4, P6936S1, P6936S2, P6936S3, P6936S4, P6936S5, P6936S6, P6936S7,
#P517,  P5264S1,  P5264S2,  P5264S3,  P5264S4,  P5264S5,  P5264S6, P6939S6, P1754

# Numericas: P5785, P5465, P203, P5328, P5322S1, P5322S2, P5322S3, P5322S4,  P5263S10,
#P5263S12, P5263S14, P5263S2

##Ahora para las continuas

filtro <- !sapply(EP_2017_clean, is.numeric)
numericas <- names(EP_2017_clean)[filtro]


for (x in numericas) {
  
  EP_2017_clean <- EP_2017_clean %>%
    mutate(x = ifelse(is.na(x), median(x, na.rm = T), x))
}

EP_2017_clean <- EP_2017_clean %>% drop_na("P5785", "P5465", "P5785", "P5465", "P203", "P5328", "P5322S1", "P5322S2", "P5322S3", "P5322S4",  "P5263S10",
                                           "P5263S14", "P5263S2")

EP_2017_clean <- EP_2017_clean  %>% 
  mutate(P4031S1A1 = if_else(is.na(P4031S1A1), 
                             calc_mode(P4031S1A1), 
                             P4031S1A1))

EP_2017_cleanF <- EP_2017_clean[c("P6933","P5785", "P5465", "P203", "P5328", "P5322S1", "P5322S2", "P5322S3", "P5322S4",  "P5263S10",
                                  "P5263S14", "P5263S2", "P4031S1A1", "P220", "P6050",  "P6160", "P6210", "P606", "P5368S2", "P5368S6", "P5334S2", "P5334S3", "P5334S4", 
                                  "P5334S7", "P5374", "P5389S10", "P5339S1", "P5321S7", "P5321S8",
                                  "P5323", "P6936S1", "P6936S2", "P6936S3", "P6936S4", "P6936S5", "P6936S6", "P6936S7",
                                  "P517", "P6939S6",  "ELN 2016", "FARC 2016", "PBCO 2016",
                                  "Tasa de Inscripción de cedulas 2018 (inscritos por mil habitantes)")]

#Convertir en una binaria nuestra variable de interés

#Convertir en Dummy la variable de interés. 0 si la persona votó 1 de lo contrario
EP_2015_cleanF$P6933 <- ifelse(EP_2015_cleanF$P6933 == 1, 0, 1)
table(EP_2015_cleanF$P6933)
EP_2017_cleanF$P6933 <- ifelse(EP_2017_cleanF$P6933 == 1, 0, 1)
table(EP_2017_cleanF$P6933)

EP_2015_cleanF <- EP_2015_cleanF %>% rename(ELN = "ELN 2015")
EP_2015_cleanF <- EP_2015_cleanF %>% rename(FARC = "FARC 2015")
EP_2015_cleanF <- EP_2015_cleanF %>% rename(AUC = "AUC 2015")
EP_2015_cleanF <- EP_2015_cleanF %>% rename(InscripcionCedulas = "Tasa de Inscripción de cédulas 2015 (inscritos por mil habitantes)")

EP_2017_cleanF <- EP_2017_cleanF %>% rename(ELN = "ELN 2016")
EP_2017_cleanF <- EP_2017_cleanF %>% rename(FARC = "FARC 2016")
EP_2017_cleanF <- EP_2017_cleanF %>% rename(PBCO = "PBCO 2016")
EP_2017_cleanF <- EP_2017_cleanF %>% rename(InscripcionCedulas = "Tasa de Inscripción de cedulas 2018 (inscritos por mil habitantes)")

#---------------Estadísticas Descriptivas 


##En búsqueda de valores atípicos se realizan gráficos de cajas y análisis de correlaciones

###-----Año 2015
##Distribución  percepciones
d1 <- ggplot(EP_2015_cleanF, aes(as.factor(P6933), P5328)) +
  geom_boxplot(fill = "darkslategray3", alpha = 0.5) +
  theme_classic() +
  labs(y = "Izquierda o Derecha", x="Votó o no") +
  scale_y_continuous() +
  scale_x_discrete( ) 

##Distribución votando se puede influir en el gobierno
d2 <- ggplot(EP_2015_cleanF, aes(as.factor(P6933), P5322S1)) +
  geom_boxplot(fill = "darkslategray3", alpha = 0.5) +
  theme_classic() +
  labs(y = "Votar es útil", x="Votó o no") +
  scale_y_continuous() +
  scale_x_discrete( ) 

##Distribución las elecciones son útiles
d3 <- ggplot(EP_2015_cleanF, aes(as.factor(P6933), P5785)) +
  geom_boxplot(fill = "darkslategray3", alpha = 0.5) +
  theme_classic() +
  labs(y = "Edad", x="Votó o no") +
  scale_y_continuous() +
  scale_x_discrete( ) 

##Distribución los partidos representan a los colombianos
d4 <- ggplot(EP_2015_cleanF, aes(as.factor(P6933), P5322S2)) +
  geom_boxplot(fill = "darkslategray3", alpha = 0.5) +
  theme_classic() +
  labs(y = "¿Los partidos representan a los colombianos?", x="Votó o no") +
  scale_y_continuous() +
  scale_x_discrete( ) 

ggarrange(d1, d2, d3, d4, nrow = 2, ncol = 2)

##Hay valores de 99 que no dejan ver bien la distribución en las variables 

EP_2015_cleanF <- EP_2015_cleanF %>%
  mutate(P5322S2= ifelse(P5322S2 ==99, median(P5322S2, na.rm = T), P5322S2))
EP_2015_cleanF <- EP_2015_cleanF %>%
  mutate(P5322S1= ifelse(P5322S1 ==99, median(P5322S1, na.rm = T), P5322S1))
EP_2015_cleanF <- EP_2015_cleanF %>%
  mutate(P203= ifelse(P203 ==99, calc_mode(P203), P203))
EP_2015_cleanF <- EP_2015_cleanF %>%
  mutate(P5328= ifelse(P5328 ==99, calc_mode(P5328), P5328))

##Distribución edad y abstencionismo
d5 <- ggplot(EP_2015_cleanF, aes(as.factor(P6933), P5785)) +
  geom_boxplot(fill = "darkslategray3", alpha = 0.5) +
  theme_classic() +
  labs(y = "Edad", x="Votó o no") +
  scale_y_continuous() +
  scale_x_discrete( ) 
d5
##Distribución por sexo y abstencionismo
d6 <- ggplot(EP_2015_cleanF, aes(as.factor(P6933), fill=factor(P220))) +
  geom_bar(fill = "darkslategray3", alpha = 0.5) +
  theme_classic() +
  labs(x = "Sexo") + scale_x_discrete(labels = c("1"="Hombre", "2"="Mujer"))

d7 <- ggplot(EP_2015_cleanF, aes(x=factor(P6210), fill=factor(P6933))) +
  geom_bar(fill = "darkslategray3", alpha = 0.5) +
  theme_classic() +
  labs(x = "Nivel Educativo") + scale_x_discrete(labels = c("1"="Ninguno", "2"="Preescolar", "3"="Básica Primaria", "4"="Básica Secundaria", "5"="Media", "6"="Superior o universitaria", "99"="No sabe"))

#Tablas5
ggarrange(d5, d6, d7, nrow = 2, ncol = 1)

vartable <- st(EP_2015_cleanF, vars = c('P6933','P5785', 'P6210', 'P220', 'P5322S1', 'P203', 'P5465', 'P5328', 'P5322S2', 'P5322S3', 'P5322S4', 'P5263S10',
                                        'P5263S14','P5263S2'), labels = c("Votó o no", "Edad", "Nivel Educativo", "Sexo", "Votar genera cambios", "Recibe ingreso", "Raza", "Inclinación Política",
                                                                          "Los partidos representan", "Votar influye en el gobierno", "Políticos no se interesan", "Confia en partidos",
                                                                          "Confía en la Registraduría", "Confía en la alcaldía"))

#Tabla con estadísticas descriptivas 

stargazer(EP_2015_cleanF[ c('FARC','ELN', 'P5785', 'P5322S1', 'P5328')], type = "text", 
          digits=2, median = TRUE, iqr = TRUE,
          title="Descriptive statistics",
          covariate.labels=c("Presencia FARC", "Presencia ELN", "Edad", "Voto útil para generar cambios", "Ideología"),
          out="table1.txt")

stargazer(EP_2015_cleanF[ c('P606','P517','P5321S7','P5339S1')], type = "text", 
          digits=2, median = TRUE, iqr = TRUE,
          title="Descriptive statistics",
          covariate.labels=c("Ocupacion principal", "Info actualidad país", "Importancia elecciones", "Conteo de votos transparente"),
          out="table2.txt")
##Correlaciones
# Primero seleccionamos las columnas numéricas
#Se obtienen las correlaciones
correla <- EP_2015_cleanF[c('P6933','P6210', 'P220', 'P5785', 'P5322S1', 'P203', 'P5785', 'P5465', 'P203', 'P5328', 'P5322S1', 'P5322S2', 'P5322S3', 'P5322S4',  'P5263S10',
                            'P5263S14', 'P5263S2')]
#Se mantiene toda la tabla

corrplot(cor(correla[, unlist(lapply(correla, is.numeric))]))



#Voto o no
ggplot(EP_2015_cleanF, aes(P6933)) + labs(x = "Votó en las últimas elecciones")  + geom_bar(fill = "darkslategray3", alpha = 0.5) + scale_fill_manual(values =c("0"="Votar", "1"="No votó")) + scale_fill_manual(values = c("Votó", "No votó")) 
prop.table(table(EP_2015_cleanF$P6933))

tapply(EP_2017_cleanF$P220, EP_2017_cleanF$P6933, summary) 

ggplot(EP_2015_cleanF,aes(x = factor(P6933), fill = P220)) +
  geom_bar() + labs(x = "Votó en las últimas elecciones") + 

  EP_2015_cleanF[, as.list(summary(P6210)), by = ]
            
##-------Año 2017

d1 <- ggplot(EP_2017_cleanF, aes(as.factor(P6933), P5328)) +
  geom_boxplot(fill = "darkslategray3", alpha = 0.5) +
  theme_classic() +
  labs(y = "Izquierda o Derecha", x="Votó o no") +
  scale_y_continuous() +
  scale_x_discrete( ) 

##Distribución votando se puede influir en el gobierno
d2 <- ggplot(EP_2017_cleanF, aes(as.factor(P6933), P5263S14)) +
  geom_boxplot(fill = "darkslategray3", alpha = 0.5) +
  theme_classic() +
  labs(y = "Votar es útil", x="Votó o no") +
  scale_y_continuous() +
  scale_x_discrete( ) 

##Distribución las elecciones son útiles
d3 <- ggplot(EP_2017_cleanF, aes(as.factor(P6933), P5785)) +
  geom_boxplot(fill = "darkslategray3", alpha = 0.5) +
  theme_classic() +
  labs(y = "Edad", x="Votó o no") +
  scale_y_continuous() +
  scale_x_discrete( ) 

##Distribución los partidos representan a los colombianos
d4 <- ggplot(EP_2017_cleanF, aes(as.factor(P6933), P5263S10)) +
  geom_boxplot(fill = "darkslategray3", alpha = 0.5) +
  theme_classic() +
  labs(y = "Confía en los partidos", x="Votó o no") +
  scale_y_continuous() +
  scale_x_discrete( ) 

ggarrange(d1, d2, d3, d4, nrow = 2, ncol = 2)

##Hay valores de 99 que no dejan ver bien la distribución en las variables 

EP_2017_cleanF <- EP_2017_cleanF %>%
  mutate(P5363S14= ifelse(P5263S14 ==99, median(P5263S14, na.rm = T), P5263S14))
EP_2017_cleanF <- EP_2017_cleanF %>%
  mutate(P5263S10= ifelse(P5263S10 ==99, median(P5263S10, na.rm = T), P5263S10))
EP_2017_cleanF <- EP_2017_cleanF %>%
  mutate(P203= ifelse(P203 ==99, calc_mode(P203), P203))
EP_2017_cleanF <- EP_2017_cleanF %>%
  mutate(P5328= ifelse(P5328 ==99, calc_mode(P5328), P5328))

##Distribución edad y abstencionismo
d5 <- ggplot(EP_2017_cleanF, aes(as.factor(P6933), P5785)) +
  geom_boxplot(fill = "darkslategray3", alpha = 0.5) +
  theme_classic() +
  labs(y = "Edad") +
  scale_y_continuous() +
  scale_x_discrete( ) 
d5
##Distribución por sexo y abstencionismo
d6 <- ggplot(EP_2017_cleanF, aes(as.factor(P220), group= as.factor(P6933))) +
  geom_bar(fill = "darkslategray3", alpha = 0.5) +
  theme_classic() +
  labs(x = "Sexo") + scale_x_discrete(labels = c("1"="Hombre", "2"="Mujer"))

d7 <- ggplot(EP_2017_cleanF, aes(as.factor(P6210), group= as.factor(P6933))) +
  geom_bar(fill = "darkslategray3", alpha = 0.5) +
  theme_classic() +
  labs(x = "Nivel Educativo") + scale_x_discrete(labels = c("1"="Ninguno", "2"="Preescolar", "3"="Básica Primaria", "4"="Básica Secundaria", "5"="Media", "6"="Superior o universitaria", "99"="No sabe"))

d8 <- ggplot(EP_2017_cleanF, aes(as.factor(P6933), P5328)) +
  geom_boxplot(fill = "darkslategray3", alpha = 0.5) +
  theme_classic() +
  labs(y = "Encuestados") +
  scale_y_continuous() +
  scale_x_discrete( ) 

#Tablas5
ggarrange(d5, d6, d7, d8, nrow = 2, ncol = 2)

vartable <- st(EP_2017_cleanF, vars = c('P6933','P5785', 'P6210', 'P220', 'P5322S1', 'P203', 'P5465', 'P5328', 'P5322S2', 'P5322S3', 'P5322S4', 'P5263S10',
                                        'P5263S14','P5263S2'), labels = c("Votó o no", "Edad", "Nivel Educativo", "Sexo", "Votar genera cambios", "Recibe ingreso", "Raza", "Inclinación Política",
                                                                          "Los partidos representan", "Votar influye en el gobierno", "Políticos no se interesan", "Confia en partidos",
                                                                          "Confía en la Registraduría", "Confía en la alcaldía"))


##Correlaciones
# Primero seleccionamos las columnas numéricas
#Se obtienen las correlaciones
correla <- EP_2017_cleanF[c('P6933','P6210', 'P220', 'P5785', 'P5322S1', 'P203', 'P5785', 'P5465', 'P203', 'P5328', 'P5322S1', 'P5322S2', 'P5322S3', 'P5322S4',  'P5263S10',
                            'P5263S14', 'P5263S2')]
#Se mantiene toda la tabla

corrplot(cor(correla[, unlist(lapply(correla, is.numeric))]))



#Voto o no
ggplot(EP_2017_cleanF, aes(P6933)) + labs(x = "Votó en las últimas elecciones")  + geom_bar(fill = "darkslategray3", alpha = 0.5) + scale_fill_manual(values =c("0"="Votar", "1"="No votó"))
prop.table(table(EP_2017_cleanF$P6933))

#---------------Division de la muestra---------------

set.seed(1948)
df_train <-  EP_2015_cleanF
index <-  round(nrow(df_train)*0.3,digits=0)
#Muestra aleatorizada del  dataset y mantener el número de observaciones del indice
test.indices <- sample(1:nrow(df_train), index)
# set de entrenamiento
dff_train<-df_train[-test.indices,] 
#30% set de testeo
dff_test<-df_train[test.indices,] 
#Seleccionar el set de entrenamiento en variables independientes y dependientes
YTrain <- dff_train$P6933
XTrain <- dff_train %>% dplyr::select(-P6933)
#Seleccionar el set de testeo en variables independientes y dependientes
YTest <- dff_test$P6933
XTest <- dff_test %>% dplyr::select(- P6933)


#Revisamos si la base está desbalanceada
prop.table(table(dff_train$P6933))
#La base muestra que más del 70% de las personas votaron, por lo que está desbalanceada. Haremos una muestra balanceada
p_load(ROSE)
dff_train_bal <- ovun.sample(P6933 ~ ., data = dff_train, method="over", p=0.5, seed = 1948)
dff_train_bal <- dff_train_bal$data
YTrain_bal <- dff_train_bal$P6933
prop.table(table(dff_train_bal$P6933))

p_load(stargazer)
#Modelo 1 OLS Regresion Logistica
Modelo1 <- glm(P6933 ~ ., family = "binomial", data = dff_train)
summary(Modelo1,type="text")

VariablesImpM1 <- varImp(Modelo1, scale=TRUE)
write.csv(VariablesImpM1, "VariableImpM1.csv", row.names = FALSE)
stargazer(Modelo1, type = "text", out = "Modelo1.Txt")

mt_coeficientes_Voto <- Modelo1$coefficients %>%
  enframe(name = "predictor", value = "coeficiente")


mt_coeficientes_Voto %>%
  filter(predictor != "(Intercept)") %>%
  ggplot(aes(x = predictor, y = coeficiente)) +
  geom_col() +
  labs(title = "Coeficientes del modelo logit Decisión de Voto") +
  theme_bw() +
  theme(axis.text.x = element_text(size = 5, angle = 45))


YhatModelo1 <- predict(Modelo1, newdata = XTest, type = "response")
plogis <- plogis(YhatModelo1)
max(plogis)
min(plogis)
view(YhatModelo1)
YhatModelo1Pred <- ifelse(plogis > 0.5, 1, 0)

MLogit1 <- confusionMatrix(table(YTest, YhatModelo1Pred))

p_load(ROCR)

pred <- prediction(plogis, YTest)
perf <- performance(pred,"tpr","fpr")

aucMod1 <- performance(pred,"auc")@y.values
aucMod1

plot(perf,colorize=TRUE)


#Modelo2 Logistica Balanceando Muestra
Modelo2 <- glm(P6933 ~ ., family = "binomial", data = dff_train_bal)
summary(Modelo2)

VariablesImpM2 <- varImp(Modelo2, scale=TRUE)
write.csv(VariablesImpM2, "VariableImpM2.csv", row.names = FALSE)
stargazer(Modelo2, type = "text", out = "Modelo2.Txt")


mt_coeficientes_Voto2 <- Modelo1$coefficients %>%
  enframe(name = "predictor", value = "coeficiente")

mt_coeficientes_Voto2 %>%
  filter(predictor != "(Intercept)") %>%
  ggplot(aes(x = predictor, y = coeficiente)) +
  geom_col() +
  labs(title = "Coeficientes del modelo logit2 Decisión de Voto") +
  theme_bw() +
  theme(axis.text.x = element_text(size = 5, angle = 45))

YhatModelo2 <- predict(Modelo2, newdata = XTest, type = "response")
plogis2 <- plogis(YhatModelo1)
max(plogis2)
min(plogis2)
view(YhatModelo2)
YhatModelo2Pred2 <- ifelse(plogis > 0.5, 1, 0)

MLogit2 <- confusionMatrix(table(YTest, YhatModelo2Pred2))


pred2 <- prediction(plogis2, YTest)
perf2 <- performance(pred2,"tpr","fpr")

aucMod2 <- performance(pred2,"auc")@y.values
aucMod2

plot(perf,colorize=TRUE)


#Modelo3 Lasso
p_load(glmnet)
XTrainSparse <- model.matrix(P6933~., dff_train_bal)[,-1]

modelo_voto_lasso <- glmnet(
  x           = XTrainSparse,
  y           = YTrain_bal,
  family = "binomial",
  alpha       = 1,
  nlambda     = 100,
  standardize = TRUE
)

regularizacion_lasso_voto <- modelo_voto_lasso$beta %>% 
  as.matrix() %>%
  t() %>% 
  as_tibble() %>%
  mutate(lambda = modelo_voto_lasso$lambda)

regularizacion_lasso_voto <- regularizacion_lasso_voto %>%
  pivot_longer(
    cols = !lambda, 
    names_to = "predictor",
    values_to = "coeficientes"
  )
regularizacion_lasso_voto %>%
  ggplot(aes(x = lambda, y = coeficientes, color = predictor)) +
  geom_line() +
  scale_x_log10(
    breaks = trans_breaks("log10", function(x) 10^x),
    labels = trans_format("log10", math_format(10^.x))
  ) +
  labs(title = "Coeficientes del modelo en función de la regularización del voto") +
  theme_bw() +
  theme(legend.position = "none")

set.seed(0711)
cv_error_lasso_voto <- cv.glmnet(
  x      = XTrainSparse,
  y      = YTrain_bal,
  family = "binomial",
  alpha  = 1,
  nfolds = 10,
  standardize  = TRUE
)

plot(cv_error_lasso_voto)

#Mejor Lambda
cv_error_lasso_voto$lambda.min

#Estimacion de modelo con lambda optimo 
modelo_op_lasso_voto <- glmnet(
  x           = XTrainSparse,
  y           = YTrain_bal,
  family = "binomial",
  alpha       = 1,
  lambda      = cv_error_lasso_voto$lambda.min,
  standardize = TRUE)



#Coeficientes 
df_coef_lasso <- coef(modelo_op_lasso_voto) %>%
  as.matrix() %>%
  as_tibble(rownames = "predictor") %>%
  rename(coeficiente = s0)

write.csv(df_coef_lasso, "CoeficientesLasso.csv", row.names = FALSE)

df_coef_lasso%>%
  filter(predictor != "(Intercept)") %>%
  ggplot(aes(x = predictor, y = coeficiente)) +
  geom_col() +
  labs(title = "Coeficientes del modelo Lasso") +
  theme_bw() +
  theme(axis.text.x = element_text(size = 6, angle = 45))

df_coef_lasso %>%
  filter(
    predictor != "(Intercept)",
    coeficiente != 0)

XTestSparse <- model.matrix(P6933~., dff_test)[,-1]
predlasso <- predict(modelo_op_lasso_voto, s = cv_error_lasso_voto$lambda.min, XTestSparse, type = "class" )
predlassoProb <- predict(modelo_op_lasso_voto, s = cv_error_lasso_voto$lambda.min, XTestSparse, type = "response" )
MLasso <- confusionMatrix(table(YTest, predlasso))

predictionlasso <- prediction(predlassoProb, YTest)
perflasso <- performance(predictionlasso,"tpr","fpr")

aucLasso <- performance(predictionlasso,"auc")@y.values
aucLasso

plot(perflasso,colorize=TRUE)



#Con los dos modelos anteriores se puede ver que hay variables que pesan más que otras. Por ejemplo en violencia FARC y ELN generan un peso significativo en los modelos
#P06, P6063, P60507, P5172, P6066, P5368S6, P6062,P5334S3, P60506, P53232, P6064 generan un impacto hacia arriba
#P6210, P5368S6, P5322S3, P6050, P6936S7, P4031S1A1, generan un impacto hacia abajo.
#Se realizará un modelo solo con estas variables


#Modelo Ridge

modelo_voto_ridge <- glmnet(
  x           = XTrainSparse,
  y           = YTrain_bal,
  family = "binomial",
  alpha       = 0,
  nlambda     = 100,
  standardize = TRUE
)

regularizacion_ridge_voto <- modelo_voto_ridge$beta %>% 
  as.matrix() %>%
  t() %>% 
  as_tibble() %>%
  mutate(lambda = modelo_voto_ridge$lambda)

regularizacion_ridge_voto <- regularizacion_ridge_voto %>%
  pivot_longer(
    cols = !lambda, 
    names_to = "predictor",
    values_to = "coeficientes"
  )
regularizacion_ridge_voto %>%
  ggplot(aes(x = lambda, y = coeficientes, color = predictor)) +
  geom_line() +
  scale_x_log10(
    breaks = trans_breaks("log10", function(x) 10^x),
    labels = trans_format("log10", math_format(10^.x))
  ) +
  labs(title = "Coeficientes del modelo en función de la regularización del voto") +
  theme_bw() +
  theme(legend.position = "none")

set.seed(0711)
cv_error_ridge_voto <- cv.glmnet(
  x      = XTrainSparse,
  y      = YTrain_bal,
  family = "binomial",
  alpha  = 0,
  nfolds = 10,
  standardize  = TRUE
)

plot(cv_error_ridge_voto)

#Mejor Lambda
cv_error_ridge_voto$lambda.min

#Estimacion de modelo con lambda optimo 
modelo_op_ridge_voto <- glmnet(
  x           = XTrainSparse,
  y           = YTrain_bal,
  family = "binomial",
  alpha       = 0,
  lambda      = cv_error_ridge_voto$lambda.min,
  standardize = TRUE)

#Coeficientes 
df_coef_ridge <- coef(modelo_op_ridge_voto) %>%
  as.matrix() %>%
  as_tibble(rownames = "predictor") %>%
  rename(coeficiente = s0)

write.csv(df_coef_ridge, "CoeficientesRidge.csv", row.names = FALSE)

df_coef_ridge%>%
  filter(predictor != "(Intercept)") %>%
  ggplot(aes(x = predictor, y = coeficiente)) +
  geom_col() +
  labs(title = "Coeficientes del modelo ridge") +
  theme_bw() +
  theme(axis.text.x = element_text(size = 6, angle = 45))

df_coef_ridge %>%
  filter(
    predictor != "(Intercept)",
    coeficiente != 0)

XTestSparse <- model.matrix(P6933~., dff_test)[,-1]
predridge <- predict(modelo_op_ridge_voto, s = cv_error_ridge_voto$lambda.min, XTestSparse, type = "class" )
predridgeProb <- predict(modelo_op_ridge_voto, s = cv_error_ridge_voto$lambda.min, XTestSparse, type = "response" )
MRidge <- confusionMatrix(table(YTest, predridge))

predictionridge <- prediction(predridgeProb, YTest)
perfridge <- performance(predictionridge,"tpr","fpr")

aucridge <- performance(predictionridge,"auc")@y.values
aucridge

plot(perfridge,colorize=TRUE)


#Modelo AdaBoost

set.seed(1410)
fiveStats <- function(...) c(twoClassSummary(...), defaultSummary(...))
ctrl<- trainControl(method = "cv",
                    number = 5,
                    summaryFunction = fiveStats,
                    classProbs = TRUE,
                    verbose=FALSE,
                    savePredictions = T)


grid_default <- expand.grid(nrounds = c(250,500),
                            max_depth = c(4,5,6),
                            eta = c(0.05),
                            gamma = c(0.01),
                            min_child_weight = c(10, 25, 50),
                            colsample_bytree = c(0.7),
                            subsample = c(0.6))

p_load()

dff_train_bal$P6933 <- as.factor(dff_train_bal$P6933)
dff_train_bal$Voto <- ifelse(dff_train_bal$P6933 == 0, "Si", "No")
dff_train_bal$Voto <- as.factor(dff_train_bal$Voto)

ModeloXG  <- train(
  Voto ~ FARC+ ELN + P606 + P6050 + P517 + P5368S6 + P5334S3 + P5323 + P6210 + P5368S6 + P6936S7,
  data = dff_train_bal,
  method = "xgbTree",
  trControl = ctrl,
  metric = "Sens",
  family = "binomial",
  tune_grid = grid_default,
  preProcess = c("center", "scale")
)

plot(ModeloXG)
ModeloXG
varImpXG <- varImp(ModeloXG,scale=TRUE)
write.csv(varImpXG$importance, "varImpXG.csv", row.names = TRUE)

YhatXG <- predict(ModeloXG, XTest)
YhatXGProb <- predict(ModeloXG, XTest, type ="prob")
VotoTest <- ifelse(YTest == 0, "Si", "No")
VotoTest <- as.factor(VotoTest)
MXG <- confusionMatrix(table(VotoTest, YhatXG))

predictionXGBoost <- prediction(YhatXGProb$No, YTest)
perfXG <- performance(predictionXGBoost,"tpr","fpr")

aucXGBoost <- performance(predictionXGBoost,"auc")@y.values
aucXGBoost

plot(perfXG,colorize=TRUE)



#--Modelo XGBoost con todas la variables
dff_train_bal2 <- dff_train_bal[,-1]

ModeloXG2  <- train(
  Voto ~ .,
  data = dff_train_bal2,
  method = "xgbTree",
  trControl = ctrl,
  metric = "Sens",
  family = "binomial",
  tune_grid = grid_default,
  preProcess = c("center", "scale")
)

plot(ModeloXG2)
ModeloXG2
varImpXG2 <- varImp(ModeloXG2,scale=TRUE)
write.csv(varImpXG2$importance, "varImpXG2.csv", row.names = TRUE)

YhatXG2 <- predict(ModeloXG2, XTest)
YhatXG2Prob <- predict(ModeloXG, XTest, type ="prob")
MXG2 <- confusionMatrix(table(VotoTest, YhatXG2))

predictionXGBoost2 <- prediction(YhatXG2Prob$No, YTest)
perfXG2 <- performance(predictionXGBoost2,"tpr","fpr")

aucXGBoost2 <- performance(predictionXGBoost2,"auc")@y.values
aucXGBoost2

plot(perfXG2,colorize=TRUE)

#------Comparación----------------

aucMod1
aucMod2
aucLasso
aucridge
aucXGBoost
aucXGBoost2

AccM1 <-MLogit1$overall[1]
SensM1 <-MLogit1$byClass[2]
NegPredValM1 <- MLogit1$byClass[4]

AccM2 <-MLogit2$overall[1]
SensM2 <-MLogit2$byClass[2]
NegPredValM2 <- MLogit2$byClass[4]

AccLasso <-MLasso$overall[1]
SensLasso <-MLasso$byClass[2]
NegPredValLasso <- MLasso$byClass[4]

AccRidge <-MRidge$overall[1]
SensRidge <-MRidge$byClass[2]
NegPredValRidge <- MRidge$byClass[4]

AccXGB <-MXG$overall[1]
SensXGB <-MXG$byClass[1]
NegPredValXGB <- MXG$byClass[3]

AccXGB2 <-MXG2$overall[1]
SensXGB2 <-MXG2$byClass[1]
NegPredValXGB2 <- MXG2$byClass[3]


Logit1 <- c(AccM1, SensM1, NegPredValM1, aucMod1)
Logit2 <- c(AccM2, SensM2, NegPredValM2, aucMod2)
LassoR <- c(AccLasso, SensLasso, NegPredValLasso, aucLasso)
RidgeR <- c(AccRidge, SensRidge, NegPredValRidge, aucridge)
XGB1 <- c(AccXGB, SensXGB, NegPredValXGB, aucXGBoost)
XGB2 <- c(AccXGB2, SensXGB2, NegPredValXGB2, aucXGBoost2)


ResultadosEstadisticos <- rbind(Logit1, Logit2, LassoR, RidgeR, XGB1, XGB2)
class(ResultadosEstadisticos)
write.csv(ResultadosEstadisticos, "EstFinales.csv", row.names = T)
ResultadosEstadisticos <- as.data.frame(ResultadosEstadisticos)
class(ResultadosEstadisticos)
ResultadosEstadisticos <-ResultadosEstadisticos %>% rename(AUC = V4)

#-----Resultados en el 2017--------------------

Voto2017 <- ifelse(EP_2017_cleanF$P6933 == 0, "Si", "No")
EP_2017_cleanF$AUC <- EP_2017_clean$`AU ELN 2018`
X2017 <- EP_2017_cleanF %>% dplyr::select(-P6933)

str(dff_train_bal2$P5322S1)
str(dff_train_bal2$P5322S2)
str(dff_train_bal$P6210)
str(dff_train_bal2$P5321S7)
str(dff_train_bal2$P5321S8)

str(X2017$P5322S1)
str(X2017$P5322S2)
str(X2017$P6210)
str(X2017$P5321S7)
str(X2017$P5321S8)

X2017$P5322S1 <- as.numeric(X2017$P5322S1)
X2017$P5322S2 <- as.numeric(X2017$P5322S2)
X2017$P6210 <- as.factor(X2017$P6210)
X2017$P5321S7 <- as.numeric(X2017$P5321S7)
X2017$P5321S8 <- as.numeric(X2017$P5321S8)

VotoHat2017 <- predict(ModeloXG2, newdata = X2017)

MFinal <- confusionMatrix(table(Voto2017, VotoHat2017))

stargazer(MFinal$table, type = "text", out = "MatrizFinal.Txt")
stargazer(MFinal$overall, type = "text", out = "MatrizFinalAccuracy.Txt")
stargazer(MFinal$byClass, type = "text", out = "MatrizFinalClass.Txt")
